{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Setup Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Spark for Your Notebook\n",
    "* This examples uses the local Spark Master `--master local[1]`\n",
    "* In production, you would use the PipelineIO Spark Master `--master spark://apachespark-master-2-1-0:7077`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--master local[1] --conf spark.cores.max=1 --conf spark.executor.memory=512m --packages com.amazonaws:aws-java-sdk:1.7.4,org.apache.hadoop:hadoop-aws:2.7.1 --jars /root/lib/jpmml-sparkml-package-1.0-SNAPSHOT.jar --py-files /root/lib/jpmml.py pyspark-shell\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "master = '--master local[1]'\n",
    "#master = '--master spark://apachespark-master-2-1-0:7077'\n",
    "conf = '--conf spark.cores.max=1 --conf spark.executor.memory=512m'\n",
    "packages = '--packages com.amazonaws:aws-java-sdk:1.7.4,org.apache.hadoop:hadoop-aws:2.7.1'\n",
    "jars = '--jars /root/lib/jpmml-sparkml-package-1.0-SNAPSHOT.jar'\n",
    "py_files = '--py-files /root/lib/jpmml.py'\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = master \\\n",
    "  + ' ' + conf \\\n",
    "  + ' ' + packages \\\n",
    "  + ' ' + jars \\\n",
    "  + ' ' + py_files \\\n",
    "  + ' ' + 'pyspark-shell'\n",
    "\n",
    "print(os.environ['PYSPARK_SUBMIT_ARGS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Spark Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import RFormula\n",
    "from pyspark.ml.classification import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Spark Session\n",
    "This may take a minute or two.  Please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "sparkSession = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Training Data into Spark Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data from Public S3 Bucket\n",
    "* AWS credentials are not needed.\n",
    "* We're asking Spark to infer the schema\n",
    "* The data has a header\n",
    "* Using `bzip2` because it's a splittable compression file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(age=39, workclass='State-gov', education='Bachelors', education_num=13, marital_status='Never-married', occupation='Adm-clerical', relationship='Not-in-family', race='White', sex='Male', capital_gain=2174, capital_loss=0, hours_per_week=40, native_country='United-States', income='<=50K')"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sparkSession.read.format(\"csv\") \\\n",
    "  .option(\"inferSchema\", \"true\").option(\"header\", \"true\") \\\n",
    "  .load(\"s3a://datapalooza/R/census.csv\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198576\n"
     ]
    }
   ],
   "source": [
    "print(df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Feature Engineering\n",
    "Already engineered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineModel_4eaf9a759b5c91517475\n"
     ]
    }
   ],
   "source": [
    "formula = RFormula(formula = \"income ~ .\")\n",
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "pipeline = Pipeline(stages = [formula, classifier])\n",
    "\n",
    "pipelineModel = pipeline.fit(data)\n",
    "\n",
    "print(pipelineModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4:  Export the Pipeline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from jpmml import toPMMLBytes\n",
    "\n",
    "model = toPMMLBytes(spark, training_dataset, pipeline_model)\n",
    "\n",
    "with open('census.model', 'wb') as fh:\n",
    "    fh.write(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5:  Deploy the Pipeline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment Option 1 of 2:  Use PipelineIO Command Line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "pip install -q pio-cli==0.37"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure CLI for Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(\"Merging dict '{'model_output_mime_type': 'application/json', \"\n",
      " \"'model_namespace': 'default', 'model_type': 'pmml', 'model_name': \"\n",
      " \"'census-cli', 'model_input_mime_type': 'application/json', \"\n",
      " \"'model_server_url': 'http://prediction-jvm.demo.pipeline.io'}' with existing \"\n",
      " \"config '/root/.pio/config'.\")\n",
      "---\n",
      "model_input_mime_type: application/json\n",
      "model_name: census-cli\n",
      "model_namespace: default\n",
      "model_output_mime_type: application/json\n",
      "model_server_url: http://prediction-jvm.demo.pipeline.io\n",
      "model_type: pmml\n",
      "pio_api_version: v1\n",
      "pio_git_home: https://github.com/fluxcapacitor/pipeline/\n",
      "pio_git_version: v1.2.0\n",
      "\n",
      "\n",
      "\n",
      "{'model_input_mime_type': 'application/json',\n",
      " 'model_name': 'census-cli',\n",
      " 'model_namespace': 'default',\n",
      " 'model_output_mime_type': 'application/json',\n",
      " 'model_server_url': 'http://prediction-jvm.demo.pipeline.io',\n",
      " 'model_type': 'pmml',\n",
      " 'pio_api_version': 'v1',\n",
      " 'pio_git_home': 'https://github.com/fluxcapacitor/pipeline/',\n",
      " 'pio_git_version': 'v1.2.0'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "pio init-model --model-server-url=http://prediction-jvm.demo.pipeline.io \\\n",
    "    --model-type=pmml --model-namespace=default --model-name=census-cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_version: v0\n",
      "model_path: /root/volumes/source.ml/jupyterhub.ml/notebooks/spark/census.model\n",
      "request_timeout: 600\n",
      "\n",
      "Deploying model '/root/volumes/source.ml/jupyterhub.ml/notebooks/spark/census.model' to 'http://prediction-jvm.demo.pipeline.io/api/v1/model/deploy/pmml/default/census-cli/v0'.\n",
      "\n",
      "\n",
      "Success!\n",
      "\n",
      "Predict with 'pio predict' or POST to 'http://prediction-jvm.demo.pipeline.io/api/v1/model/deploy/pmml/default/census-cli/v0'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "pio deploy --model-version=v0 census.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment Option 2 of 2:  REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "deploy_url = 'http://prediction-jvm.demo.pipeline.io/api/v1/model/deploy/pmml/default/census-rest/v0'\n",
    "\n",
    "files = {'file': open('census.model', 'rb')}\n",
    "\n",
    "response = requests.post(deploy_url, files=files)\n",
    "\n",
    "print(\"Success! %s\" % response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6:  Predict With Deployed Pipeline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Prediction Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"age\":39,\n",
    "        \"workclass\":\"State-gov\",\n",
    "        \"education\":\"Bachelors\",\n",
    "        \"education_num\":13,\n",
    "        \"marital_status\":\"Never-married\",\n",
    "        \"occupation\":\"Adm-clerical\",\n",
    "        \"relationship\":\"Not-in-family\",\n",
    "        \"race\":\"White\",\n",
    "        \"sex\":\"Male\",\n",
    "        \"capital_gain\":2174,\n",
    "        \"capital_loss\":0,\n",
    "        \"hours_per_week\":40,\n",
    "        \"native_country\":\"United-States\"}\n",
    "\n",
    "json_data = json.dumps(data)\n",
    "\n",
    "with open('census-predict-inputs.json', 'wt') as fh:\n",
    "    fh.write(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_version: v0\n",
      "model_input_filename: census-predict-inputs.json\n",
      "request_timeout: 30\n",
      "\n",
      "Predicting file 'census-predict-inputs.json' with model 'pmml/default/census-cli/v0' at 'http://prediction-jvm.demo.pipeline.io/api/v1/model/predict/pmml/default/census-cli/v0'...\n",
      "\n",
      "('{\"timestamp\":1494020447799,\"status\":500,\"error\":\"Internal Server '\n",
      " 'Error\",\"exception\":\"java.lang.NoClassDefFoundError\",\"message\":\"io/pipeline/prediction/jvm/PMMLEvaluationCommand\",\"path\":\"/api/v1/model/predict/pmml/default/census-cli/v0\"}')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "pio predict --model-version=v0 \\\n",
    "            --model-input-filename=census-predict-inputs.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"results\":[[{'income': 'NodeScoreDistribution{result=<=50K, probability_entries=[<=50K=0.9564524694636218, >50K=0.04354753053637812], entityId=7, confidence_entries=[]}'}]]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Note:  You may need to run this twice.\n",
    "#        A fallback will trigger the first time. (Bug)\n",
    "#predict_url = 'http://prediction-jvm.demo.pipeline.io/api/v1/model/predict/pmml/default/census-cli/v0'\n",
    "\n",
    "predict_url = 'http://prediction-jvm.demo.pipeline.io/api/v1/model/predict/pmml/default/pmml_census/v0'\n",
    "\n",
    "headers = {'content-type': 'application/json'}\n",
    "\n",
    "response = requests.post(predict_url, \n",
    "                         data=json_data, \n",
    "                         headers=headers)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7:  Monitor Model Servers through Dashboards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fallbacks and Circuit Breaker [Dashboard](http://hystrix.demo.pipeline.io/hystrix-dashboard/monitor/monitor.html?streams=%5B%7B%22name%22%3A%22Model%20Servers%22%2C%22stream%22%3A%22http%3A%2F%2Fturbine.demo.pipeline.io%2Fturbine.stream%22%2C%22auth%22%3A%22%22%2C%22delay%22%3A%22%22%7D%5D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe width=800 height=600 src=\"http://hystrix.demo.pipeline.io/hystrix-dashboard/monitor/monitor.html?streams=%5B%7B%22name%22%3A%22Model%20Servers%22%2C%22stream%22%3A%22http%3A%2F%2Fturbine.demo.pipeline.io%2Fturbine.stream%22%2C%22auth%22%3A%22%22%2C%22delay%22%3A%22%22%7D%5D\"></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<iframe width=800 height=600 src=\"http://hystrix.demo.pipeline.io/hystrix-dashboard/monitor/monitor.html?streams=%5B%7B%22name%22%3A%22Model%20Servers%22%2C%22stream%22%3A%22http%3A%2F%2Fturbine.demo.pipeline.io%2Fturbine.stream%22%2C%22auth%22%3A%22%22%2C%22delay%22%3A%22%22%7D%5D\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafana Prediction Metrics [Dashboard](http://grafana.demo.pipeline.io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe width=800 height=600 src=\"http://grafana.demo.pipeline.io\"></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<iframe width=800 height=600 src=\"http://grafana.demo.pipeline.io\"></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
