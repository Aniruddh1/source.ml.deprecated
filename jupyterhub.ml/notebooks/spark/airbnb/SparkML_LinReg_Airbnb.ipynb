{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Setup Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Spark for Your Notebook\n",
    "* You may need to Reconnect and/or Restart the Kernel to pick up changes.\n",
    "* This examples uses the local Spark Master `--master local[1]`\n",
    "* In production, you would use the PipelineIO Spark Master `--master spark://apachespark-master-2-1-0:7077`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "master = '--master local[1]'\n",
    "#master = '--master spark://apachespark-master-2-1-0:7077'\n",
    "conf = '--conf spark.cores.max=1 --conf spark.executor.memory=512m'\n",
    "#packages = '--packages com.amazonaws:aws-java-sdk:1.7.4,org.apache.hadoop:hadoop-aws:2.7.1'\n",
    "packages = ''\n",
    "jars = '--jars lib/jpmml-sparkml-package-1.0-SNAPSHOT.jar'\n",
    "py_files = '--py-files lib/jpmml.py,lib/pio_bundler.py'\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = master \\\n",
    "  + ' ' + conf \\\n",
    "  + ' ' + packages \\\n",
    "  + ' ' + jars \\\n",
    "  + ' ' + py_files \\\n",
    "  + ' ' + 'pyspark-shell'\n",
    "\n",
    "print(os.environ['PYSPARK_SUBMIT_ARGS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Spark Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Spark Session\n",
    "This may take a minute or two.  Please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark_session = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Training Data into Spark Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data from Public S3 Bucket\n",
    "* AWS credentials are not needed.\n",
    "* We're asking Spark to infer the schema\n",
    "* The data has a header\n",
    "* Using `bzip2` because it's a splittable compression file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(id=5731498, name='A 2-bdrm house in Plaka of Athens', space='Ideally located a unique house in a very peaceful neighborhood of Plaka, near Acropolis. It is a traditional house in the heart of the historical center of Athens, in Plaka. The kitchen is fully equipped with oven, fridge with freezer. Cutlery, dishes and pans, kettle, espresso coffee maker (espresso capsules are provided), toaster. There is also a vacuum cleaner and a laundry machine. One big closet will make your stay more comfortable. Bed linen, towels and bath amenities are provided. Moreover, the apartment is fully airconditioned. The apartment is very close to a greek traditional tavernas, a pharmacy, banks and public transport.  Airport or any other transport is available upon demand at an additional but very reasonable cost. ', price='120.0', bathrooms='1.0', bedrooms='2.0', room_type='Entire home/apt', square_feet=None, host_is_super_host='0.0', city='Athina', state=None, cancellation_policy='moderate', security_deposit='200.0', cleaning_fee='20.0', extra_people='15.0', minimum_nights='2', first_review='2015-04-07', instant_bookable='1.0', number_of_reviews='16', review_scores_rating='94.0', price_per_bedroom='60.0')\n"
     ]
    }
   ],
   "source": [
    "df = spark_session.read.format(\"csv\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .load(\"airbnb.csv.bz2\")\n",
    "#    .load(\"s3a://datapalooza/airbnb/airbnb.csv.bz2\")\n",
    "\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198576\n"
     ]
    }
   ],
   "source": [
    "print(df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean, Filter, and Summarize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+------------------+-----------------+\n",
      "|summary|      square_feet|             price|          bedrooms|         bathrooms|     cleaning_fee|\n",
      "+-------+-----------------+------------------+------------------+------------------+-----------------+\n",
      "|  count|           151864|            151864|            151864|            151864|           151864|\n",
      "|   mean|545.5920823895063|131.00769109202972|1.3336998893747036|1.1988786019069695|37.25118527103198|\n",
      "| stddev|363.2346181084825| 89.59372969879449|0.8460907193971746|0.4836515839573332|  42.625502170779|\n",
      "|    min|            104.0|              50.0|               0.0|               0.5|              0.0|\n",
      "|    max|          32292.0|             750.0|              10.0|               8.0|            700.0|\n",
      "+-------+-----------------+------------------+------------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered = df.filter(\"price >= 50 AND price <= 750 AND bathrooms > 0.0 AND bedrooms is not null\")\n",
    "\n",
    "df_filtered.registerTempTable(\"df_filtered\")\n",
    "\n",
    "df_final = spark_session.sql(\"\"\"\n",
    "    select\n",
    "        id,\n",
    "        city,\n",
    "        case when state in('NY', 'CA', 'London', 'Berlin', 'TX' ,'IL', 'OR', 'DC', 'WA')\n",
    "            then state\n",
    "            else 'Other'\n",
    "        end as state,\n",
    "        space,\n",
    "        cast(price as double) as price,\n",
    "        cast(bathrooms as double) as bathrooms,\n",
    "        cast(bedrooms as double) as bedrooms,\n",
    "        room_type,\n",
    "        host_is_super_host,\n",
    "        cancellation_policy,\n",
    "        cast(case when security_deposit is null\n",
    "            then 0.0\n",
    "            else security_deposit\n",
    "        end as double) as security_deposit,\n",
    "        price_per_bedroom,\n",
    "        cast(case when number_of_reviews is null\n",
    "            then 0.0\n",
    "            else number_of_reviews\n",
    "        end as double) as number_of_reviews,\n",
    "        cast(case when extra_people is null\n",
    "            then 0.0\n",
    "            else extra_people\n",
    "        end as double) as extra_people,\n",
    "        instant_bookable,\n",
    "        cast(case when cleaning_fee is null\n",
    "            then 0.0\n",
    "            else cleaning_fee\n",
    "        end as double) as cleaning_fee,\n",
    "        cast(case when review_scores_rating is null\n",
    "            then 80.0\n",
    "            else review_scores_rating\n",
    "        end as double) as review_scores_rating,\n",
    "        cast(case when square_feet is not null and square_feet > 100\n",
    "            then square_feet\n",
    "            when (square_feet is null or square_feet <=100) and (bedrooms is null or bedrooms = 0)\n",
    "            then 350.0\n",
    "            else 380 * bedrooms\n",
    "        end as double) as square_feet\n",
    "    from df_filtered\n",
    "\"\"\").persist()\n",
    "\n",
    "df_final.registerTempTable(\"df_final\")\n",
    "\n",
    "df_final.select(\"square_feet\", \"price\", \"bedrooms\", \"bathrooms\", \"cleaning_fee\").describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151864\n"
     ]
    }
   ],
   "source": [
    "print(df_final.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(List(StructField(id,IntegerType,true),StructField(city,StringType,true),StructField(state,StringType,true),StructField(space,StringType,true),StructField(price,DoubleType,true),StructField(bathrooms,DoubleType,true),StructField(bedrooms,DoubleType,true),StructField(room_type,StringType,true),StructField(host_is_super_host,StringType,true),StructField(cancellation_policy,StringType,true),StructField(security_deposit,DoubleType,true),StructField(price_per_bedroom,StringType,true),StructField(number_of_reviews,DoubleType,true),StructField(extra_people,DoubleType,true),StructField(instant_bookable,StringType,true),StructField(cleaning_fee,DoubleType,true),StructField(review_scores_rating,DoubleType,true),StructField(square_feet,DoubleType,true)))\n"
     ]
    }
   ],
   "source": [
    "print(df_final.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+------------------+---------+\n",
      "| state|   ct|         avg_price|max_price|\n",
      "+------+-----+------------------+---------+\n",
      "| Other|87467|122.00503046863389|    750.0|\n",
      "|    NY|22899| 145.9446264028997|    750.0|\n",
      "|    CA|20750|157.40173493975902|    750.0|\n",
      "|Berlin| 6034|  80.6433543254889|    650.0|\n",
      "|    IL| 3552|141.46903153153153|    690.0|\n",
      "|    TX| 3108|195.25611325611325|    750.0|\n",
      "|    WA| 2700| 131.4962962962963|    750.0|\n",
      "|    DC| 2590|136.64015444015445|    720.0|\n",
      "|    OR| 1954|114.02661207778915|    700.0|\n",
      "|London|  810|108.84444444444445|    600.0|\n",
      "+------+-----+------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Most popular cities\n",
    "\n",
    "spark_session.sql(\"\"\"\n",
    "    select \n",
    "        state,\n",
    "        count(*) as ct,\n",
    "        avg(price) as avg_price,\n",
    "        max(price) as max_price\n",
    "    from df_final\n",
    "    group by state\n",
    "    order by count(*) desc\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+------------------+---------+\n",
      "|               city| ct|         avg_price|max_price|\n",
      "+-------------------+---+------------------+---------+\n",
      "|         Palm Beach| 26| 348.7692307692308|    701.0|\n",
      "|        Watsonville| 38| 313.3157894736842|    670.0|\n",
      "|             Malibu|136| 280.9852941176471|    750.0|\n",
      "|             Avalon| 38|262.42105263157896|    701.0|\n",
      "|           Capitola| 35|             246.4|    650.0|\n",
      "|           Tamarama| 72|             238.5|    750.0|\n",
      "|    Manhattan Beach|109|232.10091743119267|    700.0|\n",
      "|Rancho Palos Verdes| 39|230.02564102564102|    750.0|\n",
      "|       Avalon Beach| 38|229.60526315789474|    620.0|\n",
      "|            Newport| 52| 223.8653846153846|    750.0|\n",
      "|      Darling Point| 29|221.51724137931035|    623.0|\n",
      "|        Middle Park| 34| 212.7941176470588|    671.0|\n",
      "|            Balmain| 55|212.56363636363636|    712.0|\n",
      "|        North Bondi|180|206.68333333333334|    750.0|\n",
      "|             Bronte|144|203.70833333333334|    750.0|\n",
      "|        Queenscliff| 40|           201.925|    650.0|\n",
      "|          Lilyfield| 26|198.92307692307693|    701.0|\n",
      "|         Freshwater| 54| 198.5185185185185|    650.0|\n",
      "|           La Jolla| 52|197.82692307692307|    649.0|\n",
      "|     Marina del Rey|205| 196.6390243902439|    550.0|\n",
      "+-------------------+---+------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Most expensive popular cities\n",
    "\n",
    "spark_session.sql(\"\"\"\n",
    "    select \n",
    "        city,\n",
    "        count(*) as ct,\n",
    "        avg(price) as avg_price,\n",
    "        max(price) as max_price\n",
    "    from df_final\n",
    "    group by city\n",
    "    order by avg(price) desc\n",
    "\"\"\").filter(\"ct > 25\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "continuous_features = [\"bathrooms\", \\\n",
    "                       \"bedrooms\", \\\n",
    "                       \"security_deposit\", \\\n",
    "                       \"cleaning_fee\", \\\n",
    "                       \"extra_people\", \\\n",
    "                       \"number_of_reviews\", \\\n",
    "                       \"square_feet\", \\\n",
    "                       \"review_scores_rating\"]\n",
    "\n",
    "categorical_features = [\"room_type\", \\\n",
    "                        \"host_is_super_host\", \\\n",
    "                        \"cancellation_policy\", \\\n",
    "                        \"instant_bookable\", \\\n",
    "                        \"state\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "continuous_feature_assembler = VectorAssembler(inputCols=continuous_features, outputCol=\"unscaled_continuous_features\")\n",
    "\n",
    "continuous_feature_scaler = StandardScaler(inputCol=\"unscaled_continuous_features\", outputCol=\"scaled_continuous_features\", \\\n",
    "                                           withStd=True, withMean=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_feature_indexers = [StringIndexer(inputCol=x, \\\n",
    "                                              outputCol=\"{}_index\".format(x)) \\\n",
    "                                for x in categorical_features]\n",
    "\n",
    "categorical_feature_one_hot_encoders = [OneHotEncoder(inputCol=x.getOutputCol(), \\\n",
    "                                                      outputCol=\"oh_encoder_{}\".format(x.getOutputCol() )) \\\n",
    "                                        for x in categorical_feature_indexers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble Continuous and Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_cols_lr = [x.getOutputCol() \\\n",
    "                   for x in categorical_feature_one_hot_encoders]\n",
    "feature_cols_lr.append(\"scaled_continuous_features\")\n",
    "\n",
    "feature_assembler_lr = VectorAssembler(inputCols=feature_cols_lr, \\\n",
    "                                       outputCol=\"features_lr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineModel_4c6487842fe5f0df9f58\n"
     ]
    }
   ],
   "source": [
    "linear_regression = LinearRegression(featuresCol=\"features_lr\", \\\n",
    "                                     labelCol=\"price\", \\\n",
    "                                     predictionCol=\"price_prediction\", \\\n",
    "                                     maxIter=10, \\\n",
    "                                     regParam=0.3, \\\n",
    "                                     elasticNetParam=0.8)\n",
    "\n",
    "estimators_lr = \\\n",
    "  [continuous_feature_assembler, continuous_feature_scaler] \\\n",
    "  + categorical_feature_indexers + categorical_feature_one_hot_encoders \\\n",
    "  + [feature_assembler_lr] + [linear_regression]\n",
    "\n",
    "pipeline = Pipeline(stages=estimators_lr)\n",
    "\n",
    "pipeline_model = pipeline.fit(df_final)\n",
    "\n",
    "print(pipeline_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_model.write().overwrite().save(\"airbnb.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.types.StructType"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_final.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dill as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('airbnb.schema', 'wb') as pkl_file:\n",
    "    pickle.dump(df_final.schema, pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "�\u0003cpyspark.sql.types\r\n",
      "StructType\r\n",
      "q\u0000)�q\u0001}q\u0002(X\u0006\u0000\u0000\u0000fieldsq\u0003]q\u0004(cpyspark.sql.types\r\n",
      "StructField\r\n",
      "q\u0005)�q\u0006}q\u0007(X\b\u0000\u0000\u0000nullableq\b�X\b\u0000\u0000\u0000metadataq\t}q\r\n",
      "X\b\u0000\u0000\u0000dataTypeq\u000b",
      "cpyspark.sql.types\r\n",
      "IntegerType\r\n",
      "q\f",
      ")�q\r",
      "X\u0004\u0000\u0000\u0000nameq\u000eX\u0002\u0000\u0000\u0000idq\u000fubh\u0005)�q\u0010}q\u0011(h\b�h\t}q\u0012h\u000b",
      "cpyspark.sql.types\r\n",
      "StringType\r\n",
      "q\u0013)�q\u0014h\u000eX\u0004\u0000\u0000\u0000cityq\u0015ubh\u0005)�q\u0016}q\u0017(h\b�h\t}q\u0018h\u000b",
      "h\u0013)�q\u0019h\u000eX\u0005\u0000\u0000\u0000stateq\u001aubh\u0005)�q\u001b}q\u001c",
      "(h\b�h\t}q\u001d",
      "h\u000b",
      "h\u0013)�q\u001e",
      "h\u000eX\u0005\u0000\u0000\u0000spaceq\u001fubh\u0005)�q }q!(h\b�h\t}q\"h\u000b",
      "cpyspark.sql.types\r\n",
      "DoubleType\r\n",
      "q#)�q$h\u000eX\u0005\u0000\u0000\u0000priceq%ubh\u0005)�q&}q'(h\b�h\t}q(h\u000b",
      "h#)�q)h\u000eX\t\u0000\u0000\u0000bathroomsq*ubh\u0005)�q+}q,(h\b�h\t}q-h\u000b",
      "h#)�q.h\u000eX\b\u0000\u0000\u0000bedroomsq/ubh\u0005)�q0}q1(h\b�h\t}q2h\u000b",
      "h\u0013)�q3h\u000eX\t\u0000\u0000\u0000room_typeq4ubh\u0005)�q5}q6(h\b�h\t}q7h\u000b",
      "h\u0013)�q8h\u000eX\u0012\u0000\u0000\u0000host_is_super_hostq9ubh\u0005)�q:}q;(h\b�h\t}q<h\u000b",
      "h\u0013)�q=h\u000eX\u0013\u0000\u0000\u0000cancellation_policyq>ubh\u0005)�q?}q@(h\b�h\t}qAh\u000b",
      "h#)�qBh\u000eX\u0010\u0000\u0000\u0000security_depositqCubh\u0005)�qD}qE(h\b�h\t}qFh\u000b",
      "h\u0013)�qGh\u000eX\u0011\u0000\u0000\u0000price_per_bedroomqHubh\u0005)�qI}qJ(h\b�h\t}qKh\u000b",
      "h#)�qLh\u000eX\u0011\u0000\u0000\u0000number_of_reviewsqMubh\u0005)�qN}qO(h\b�h\t}qPh\u000b",
      "h#)�qQh\u000eX\f",
      "\u0000\u0000\u0000extra_peopleqRubh\u0005)�qS}qT(h\b�h\t}qUh\u000b",
      "h\u0013)�qVh\u000eX\u0010\u0000\u0000\u0000instant_bookableqWubh\u0005)�qX}qY(h\b�h\t}qZh\u000b",
      "h#)�q[h\u000eX\f",
      "\u0000\u0000\u0000cleaning_feeq\\ubh\u0005)�q]}q^(h\b�h\t}q_h\u000b",
      "h#)�q`h\u000eX\u0014\u0000\u0000\u0000review_scores_ratingqaubh\u0005)�qb}qc(h\b�h\t}qdh\u000b",
      "h#)�qeh\u000eX\u000b",
      "\u0000\u0000\u0000square_feetqfubeX\u0005\u0000\u0000\u0000namesqg]qh(h\u000fh\u0015h\u001ah\u001fh%h*h/h4h9h>hChHhMhRhWh\\hahfeX\u0016\u0000\u0000\u0000_needSerializeAnyFieldqi�ub."
     ]
    }
   ],
   "source": [
    "!cat airbnb.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SERVE FROM HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restored_pipeline_model = PipelineModel.read().load(\"airbnb.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PipelineModel' object has no attribute 'schema'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-f4a2de3552cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestored_pipeline_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'PipelineModel' object has no attribute 'schema'"
     ]
    }
   ],
   "source": [
    "print(restored_pipeline_model.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4:  Export the Pipeline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"fields\":[{\"metadata\":{},\"name\":\"id\",\"nullable\":true,\"type\":\"integer\"},{\"metadata\":{},\"name\":\"city\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"state\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"space\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"price\",\"nullable\":true,\"type\":\"double\"},{\"metadata\":{},\"name\":\"bathrooms\",\"nullable\":true,\"type\":\"double\"},{\"metadata\":{},\"name\":\"bedrooms\",\"nullable\":true,\"type\":\"double\"},{\"metadata\":{},\"name\":\"room_type\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"host_is_super_host\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"cancellation_policy\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"security_deposit\",\"nullable\":true,\"type\":\"double\"},{\"metadata\":{},\"name\":\"price_per_bedroom\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"number_of_reviews\",\"nullable\":true,\"type\":\"double\"},{\"metadata\":{},\"name\":\"extra_people\",\"nullable\":true,\"type\":\"double\"},{\"metadata\":{},\"name\":\"instant_bookable\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"cleaning_fee\",\"nullable\":true,\"type\":\"double\"},{\"metadata\":{},\"name\":\"review_scores_rating\",\"nullable\":true,\"type\":\"double\"},{\"metadata\":{},\"name\":\"square_feet\",\"nullable\":true,\"type\":\"double\"}],\"type\":\"struct\"}'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.schema.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(List(StructField(id,IntegerType,true),StructField(city,StringType,true),StructField(state,StringType,true),StructField(space,StringType,true),StructField(price,DoubleType,true),StructField(bathrooms,DoubleType,true),StructField(bedrooms,DoubleType,true),StructField(room_type,StringType,true),StructField(host_is_super_host,StringType,true),StructField(cancellation_policy,StringType,true),StructField(security_deposit,DoubleType,true),StructField(price_per_bedroom,StringType,true),StructField(number_of_reviews,DoubleType,true),StructField(extra_people,DoubleType,true),StructField(instant_bookable,StringType,true),StructField(cleaning_fee,DoubleType,true),StructField(review_scores_rating,DoubleType,true),StructField(square_feet,DoubleType,true)))\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import _parse_datatype_json_string\n",
    "schema = _parse_datatype_json_string(df_final.schema.json())\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_needSerializeAnyField': False, 'names': ['id', 'city', 'state', 'space', 'price', 'bathrooms', 'bedrooms', 'room_type', 'host_is_super_host', 'cancellation_policy', 'security_deposit', 'price_per_bedroom', 'number_of_reviews', 'extra_people', 'instant_bookable', 'cleaning_fee', 'review_scores_rating', 'square_feet'], 'fields': [{'metadata': {}, 'nullable': True, 'dataType': {'__class__': 'pyspark.sql.types.IntegerType'}, 'name': 'id', '__class__': 'pyspark.sql.types.StructField'}, {'metadata': {}, 'nullable': True, 'dataType': {'__class__': 'pyspark.sql.types.StringType'}, 'name': 'city', '__class__': 'pyspark.sql.types.StructField'}, {'metadata': {}, 'nullable': True, 'dataType': {'__class__': 'pyspark.sql.types.StringType'}, 'name': 'state', '__class__': 'pyspark.sql.types.StructField'}, {'metadata': {}, 'nullable': True, 'dataType': {'__class__': 'pyspark.sql.types.StringType'}, 'name': 'space', '__class__': 'pyspark.sql.types.StructField'}, {'metadata': {}, 'nullable': True, 'dataType': {'__class__': 'pyspark.sql.types.DoubleType'}, 'name': 'price', '__class__': 'pyspark.sql.types.StructField'}, {'metadata': {}, 'nullable': True, 'dataType': {'__class__': 'pyspark.sql.types.DoubleType'}, 'name': 'bathrooms', '__class__': 'pyspark.sql.types.StructField'}, {'metadata': {}, 'nullable': True, 'dataType': {'__class__': 'pyspark.sql.types.DoubleType'}, 'name': 'bedrooms', '__class__': 'pyspark.sql.types.StructField'}, {'metadata': {}, 'nullable': True, 'dataType': {'__class__': 'pyspark.sql.types.StringType'}, 'name': 'room_type', '__class__': 'pyspark.sql.types.StructField'}, {'metadata': {}, 'nullable': True, 'dataType': {'__class__': 'pyspark.sql.types.StringType'}, 'name': 'host_is_super_host', '__class__': 'pyspark.sql.types.StructField'}, {'metadata': {}, 'nullable': True, 'dataType': {'__class__': 'pyspark.sql.types.StringType'}, 'name': 'cancellation_policy', '__class__': 'pyspark.sql.types.StructField'}, {'metadata': {}, 'nullable': True, 'dataType': {'__class__': 'pyspark.sql.types.DoubleType'}, 'name': 'security_deposit', '__class__': 'pyspark.sql.types.StructField'}, {'metadata': {}, 'nullable': True, 'dataType': {'__class__': 'pyspark.sql.types.StringType'}, 'name': 'price_per_bedroom', '__class__': 'pyspark.sql.types.StructField'}, {'metadata': {}, 'nullable': True, 'dataType': {'__class__': 'pyspark.sql.types.DoubleType'}, 'name': 'number_of_reviews', '__class__': 'pyspark.sql.types.StructField'}, {'metadata': {}, 'nullable': True, 'dataType': {'__class__': 'pyspark.sql.types.DoubleType'}, 'name': 'extra_people', '__class__': 'pyspark.sql.types.StructField'}, {'metadata': {}, 'nullable': True, 'dataType': {'__class__': 'pyspark.sql.types.StringType'}, 'name': 'instant_bookable', '__class__': 'pyspark.sql.types.StructField'}, {'metadata': {}, 'nullable': True, 'dataType': {'__class__': 'pyspark.sql.types.DoubleType'}, 'name': 'cleaning_fee', '__class__': 'pyspark.sql.types.StructField'}, {'metadata': {}, 'nullable': True, 'dataType': {'__class__': 'pyspark.sql.types.DoubleType'}, 'name': 'review_scores_rating', '__class__': 'pyspark.sql.types.StructField'}, {'metadata': {}, 'nullable': True, 'dataType': {'__class__': 'pyspark.sql.types.DoubleType'}, 'name': 'square_feet', '__class__': 'pyspark.sql.types.StructField'}], '__class__': 'pyspark.sql.types.StructType'}\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.common import _py2java\n",
    "\n",
    "schema_as_java = _py2java(spark_session, schema)\n",
    "print(schema_as_java)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'fromInternal'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-bad2acf335b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mrestored_spark_df_schema_as_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkl_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestored_spark_df_schema_as_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mrestored_spark_df_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestored_spark_df_schema_as_json\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromInternal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestored_spark_df_schema_as_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m#_parse_datatype_json_string(restored_spark_df_schema_as_json)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#print(restored_spark_df_schema)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'fromInternal'"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.common import _py2java\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql.types import StructType\n",
    "import dill as pickle\n",
    "\n",
    "spark_df_schema_as_json = df_final.schema.toInternal(df_final.schema)\n",
    "with open('model.schema', 'wb') as pkl_file:\n",
    "    pickle.dump(spark_df_schema_as_json, pkl_file)\n",
    "\n",
    "pipeline_model.write().overwrite().save('model.parquet')\n",
    "\n",
    "## SERVE FROM HERE\n",
    "with open('model.schema', 'rb') as pkl_file:\n",
    "    from pyspark.sql.types import _parse_datatype_json_string\n",
    "    restored_spark_df_schema_as_json = pickle.load(pkl_file)\n",
    "    print(type(restored_spark_df_schema_as_json))\n",
    "    restored_spark_df_schema = restored_spark_df_schema_as_json.fromInternal(restored_spark_df_schema_as_json)\n",
    "#_parse_datatype_json_string(restored_spark_df_schema_as_json)\n",
    "    #print(restored_spark_df_schema)\n",
    "#   restored_spark_df_schema_as_java = _py2java(spark_session, restored_spark_df_schema)\n",
    "\n",
    "restored_spark_pipeline_model = PipelineModel.read().load('model.parquet')\n",
    "restored_spark_pipeline_model_as_java = restored_spark_pipeline_model._to_java()\n",
    "\n",
    "print(spark_session._jvm.org.jpmml.sparkml.ConverterUtil.toPMMLByteArray(restored_spark_df_schema,\n",
    "                                                                          restored_spark_pipeline_model_as_java))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o358.__getstate__. Trace:\npy4j.Py4JException: Method __getstate__([]) does not exist\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\n\tat py4j.Gateway.invoke(Gateway.java:272)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-539e0d2c6703>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpio_bundler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpio_bundler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbundle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline_model_restore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/private/var/folders/_r/w1q7hhvx6dj46bmpnny4rt_r0000gn/T/spark-01d305f2-e947-403d-9ec2-21adf55e5162/userFiles-e2c27222-febd-4881-af36-2ea78f893962/pio_bundler.py\u001b[0m in \u001b[0;36mbundle\u001b[0;34m(spark_session, spark_df, spark_pipeline_model)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mspark_df_schema_as_java\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark_df_as_java\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.schema'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpkl_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark_df_schema_as_java\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpkl_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mspark_pipeline_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cfregly/miniconda3/lib/python3.5/site-packages/dill/dill.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, file, protocol, byref, fmode, recurse)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;31m# end hack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m     \u001b[0mpik\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m     \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# clear record of 'recursion-sensitive' pickled objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cfregly/miniconda3/lib/python3.5/pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cfregly/miniconda3/lib/python3.5/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__reduce_ex__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m                 \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m                 \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__reduce__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cfregly/spark-2.1.0-bin-fluxcapacitor/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cfregly/spark-2.1.0-bin-fluxcapacitor/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cfregly/spark-2.1.0-bin-fluxcapacitor/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    321\u001b[0m                 raise Py4JError(\n\u001b[1;32m    322\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}. Trace:\\n{3}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m                     format(target_id, \".\", name, value))\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             raise Py4JError(\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o358.__getstate__. Trace:\npy4j.Py4JException: Method __getstate__([]) does not exist\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\n\tat py4j.Gateway.invoke(Gateway.java:272)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\n\n"
     ]
    }
   ],
   "source": [
    "import pio_bundler\n",
    "\n",
    "pio_bundler.bundle(spark_session, df_final, pipeline_model_restore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from jpmml import toPMMLBytes\n",
    "\n",
    "model = toPMMLBytes(spark_session, df_final, pipeline_model_restore)\n",
    "\n",
    "with open('airbnb.model', 'wb') as fh:\n",
    "    fh.write(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\r\n",
      "<PMML xmlns=\"http://www.dmg.org/PMML-4_3\" version=\"4.3\">\r\n",
      "\t<Header>\r\n",
      "\t\t<Application/>\r\n",
      "\t\t<Timestamp>2017-05-21T02:37:48Z</Timestamp>\r\n",
      "\t</Header>\r\n",
      "\t<DataDictionary>\r\n",
      "\t\t<DataField name=\"bathrooms\" optype=\"continuous\" dataType=\"double\"/>\r\n",
      "\t\t<DataField name=\"bedrooms\" optype=\"continuous\" dataType=\"double\"/>\r\n",
      "\t\t<DataField name=\"security_deposit\" optype=\"continuous\" dataType=\"double\"/>\r\n",
      "\t\t<DataField name=\"cleaning_fee\" optype=\"continuous\" dataType=\"double\"/>\r\n",
      "\t\t<DataField name=\"extra_people\" optype=\"continuous\" dataType=\"double\"/>\r\n",
      "\t\t<DataField name=\"number_of_reviews\" optype=\"continuous\" dataType=\"double\"/>\r\n",
      "\t\t<DataField name=\"square_feet\" optype=\"continuous\" dataType=\"double\"/>\r\n",
      "\t\t<DataField name=\"review_scores_rating\" optype=\"continuous\" dataType=\"double\"/>\r\n",
      "\t\t<DataField name=\"room_type\" optype=\"categorical\" dataType=\"string\">\r\n",
      "\t\t\t<Value value=\"Entire home/apt\"/>\r\n",
      "\t\t\t<Value value=\"Private room\"/>\r\n",
      "\t\t\t<Value value=\"Shared room\"/>\r\n",
      "\t\t</DataField>\r\n",
      "\t\t<DataField name=\"host_is_super_host\" optype=\"categorical\" dataType=\"string\">\r\n",
      "\t\t\t<Value value=\"0.0\"/>\r\n",
      "\t\t\t<Value value=\"1.0\"/>\r\n",
      "\t\t</DataField>\r\n",
      "\t\t<DataField name=\"cancellation_policy\" optype=\"categorical\" dataType=\"string\">\r\n",
      "\t\t\t<Value value=\"strict\"/>\r\n",
      "\t\t\t<Value value=\"moderate\"/>\r\n",
      "\t\t\t<Value value=\"flexible\"/>\r\n",
      "\t\t\t<Value value=\"super_strict_30\"/>\r\n",
      "\t\t\t<Value value=\"super_strict_60\"/>\r\n",
      "\t\t\t<Value value=\"no_refunds\"/>\r\n",
      "\t\t\t<Value value=\"long_term\"/>\r\n",
      "\t\t</DataField>\r\n",
      "\t\t<DataField name=\"instant_bookable\" optype=\"categorical\" dataType=\"string\">\r\n",
      "\t\t\t<Value value=\"0.0\"/>\r\n",
      "\t\t\t<Value value=\"1.0\"/>\r\n",
      "\t\t</DataField>\r\n",
      "\t\t<DataField name=\"state\" optype=\"categorical\" dataType=\"string\">\r\n",
      "\t\t\t<Value value=\"Other\"/>\r\n",
      "\t\t\t<Value value=\"NY\"/>\r\n",
      "\t\t\t<Value value=\"CA\"/>\r\n",
      "\t\t\t<Value value=\"Berlin\"/>\r\n",
      "\t\t\t<Value value=\"IL\"/>\r\n",
      "\t\t\t<Value value=\"TX\"/>\r\n",
      "\t\t\t<Value value=\"WA\"/>\r\n",
      "\t\t\t<Value value=\"DC\"/>\r\n",
      "\t\t\t<Value value=\"OR\"/>\r\n",
      "\t\t\t<Value value=\"London\"/>\r\n",
      "\t\t</DataField>\r\n",
      "\t\t<DataField name=\"price\" optype=\"continuous\" dataType=\"double\"/>\r\n",
      "\t</DataDictionary>\r\n",
      "\t<TransformationDictionary>\r\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[0]\" optype=\"continuous\" dataType=\"double\">\r\n",
      "\t\t\t<Apply function=\"*\">\r\n",
      "\t\t\t\t<FieldRef field=\"bathrooms\"/>\r\n",
      "\t\t\t\t<Constant dataType=\"double\">2.067604104214446</Constant>\r\n",
      "\t\t\t</Apply>\r\n",
      "\t\t</DerivedField>\r\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[1]\" optype=\"continuous\" dataType=\"double\">\r\n",
      "\t\t\t<Apply function=\"*\">\r\n",
      "\t\t\t\t<FieldRef field=\"bedrooms\"/>\r\n",
      "\t\t\t\t<Constant dataType=\"double\">1.181906357172289</Constant>\r\n",
      "\t\t\t</Apply>\r\n",
      "\t\t</DerivedField>\r\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[2]\" optype=\"continuous\" dataType=\"double\">\r\n",
      "\t\t\t<Apply function=\"*\">\r\n",
      "\t\t\t\t<FieldRef field=\"security_deposit\"/>\r\n",
      "\t\t\t\t<Constant dataType=\"double\">0.005517920140843639</Constant>\r\n",
      "\t\t\t</Apply>\r\n",
      "\t\t</DerivedField>\r\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[3]\" optype=\"continuous\" dataType=\"double\">\r\n",
      "\t\t\t<Apply function=\"*\">\r\n",
      "\t\t\t\t<FieldRef field=\"cleaning_fee\"/>\r\n",
      "\t\t\t\t<Constant dataType=\"double\">0.023460134170232096</Constant>\r\n",
      "\t\t\t</Apply>\r\n",
      "\t\t</DerivedField>\r\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[4]\" optype=\"continuous\" dataType=\"double\">\r\n",
      "\t\t\t<Apply function=\"*\">\r\n",
      "\t\t\t\t<FieldRef field=\"extra_people\"/>\r\n",
      "\t\t\t\t<Constant dataType=\"double\">0.05393401572579306</Constant>\r\n",
      "\t\t\t</Apply>\r\n",
      "\t\t</DerivedField>\r\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[5]\" optype=\"continuous\" dataType=\"double\">\r\n",
      "\t\t\t<Apply function=\"*\">\r\n",
      "\t\t\t\t<FieldRef field=\"number_of_reviews\"/>\r\n",
      "\t\t\t\t<Constant dataType=\"double\">0.037120231077026486</Constant>\r\n",
      "\t\t\t</Apply>\r\n",
      "\t\t</DerivedField>\r\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[6]\" optype=\"continuous\" dataType=\"double\">\r\n",
      "\t\t\t<Apply function=\"*\">\r\n",
      "\t\t\t\t<FieldRef field=\"square_feet\"/>\r\n",
      "\t\t\t\t<Constant dataType=\"double\">0.0027530415608716654</Constant>\r\n",
      "\t\t\t</Apply>\r\n",
      "\t\t</DerivedField>\r\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[7]\" optype=\"continuous\" dataType=\"double\">\r\n",
      "\t\t\t<Apply function=\"*\">\r\n",
      "\t\t\t\t<FieldRef field=\"review_scores_rating\"/>\r\n",
      "\t\t\t\t<Constant dataType=\"double\">0.11345543327198991</Constant>\r\n",
      "\t\t\t</Apply>\r\n",
      "\t\t</DerivedField>\r\n",
      "\t</TransformationDictionary>\r\n",
      "\t<RegressionModel functionName=\"regression\">\r\n",
      "\t\t<MiningSchema>\r\n",
      "\t\t\t<MiningField name=\"price\" usageType=\"target\"/>\r\n",
      "\t\t\t<MiningField name=\"bathrooms\"/>\r\n",
      "\t\t\t<MiningField name=\"bedrooms\"/>\r\n",
      "\t\t\t<MiningField name=\"security_deposit\"/>\r\n",
      "\t\t\t<MiningField name=\"cleaning_fee\"/>\r\n",
      "\t\t\t<MiningField name=\"extra_people\"/>\r\n",
      "\t\t\t<MiningField name=\"number_of_reviews\"/>\r\n",
      "\t\t\t<MiningField name=\"square_feet\"/>\r\n",
      "\t\t\t<MiningField name=\"review_scores_rating\"/>\r\n",
      "\t\t\t<MiningField name=\"room_type\"/>\r\n",
      "\t\t\t<MiningField name=\"host_is_super_host\"/>\r\n",
      "\t\t\t<MiningField name=\"cancellation_policy\"/>\r\n",
      "\t\t\t<MiningField name=\"instant_bookable\"/>\r\n",
      "\t\t\t<MiningField name=\"state\"/>\r\n",
      "\t\t</MiningSchema>\r\n",
      "\t\t<RegressionTable intercept=\"-31.288805261574204\">\r\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[0]\" coefficient=\"16.940142871985664\"/>\r\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[1]\" coefficient=\"21.545989482256857\"/>\r\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[2]\" coefficient=\"1.0249092075804178\"/>\r\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[3]\" coefficient=\"24.315049381821773\"/>\r\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[4]\" coefficient=\"2.5700114323866092\"/>\r\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[5]\" coefficient=\"-2.722647547334265\"/>\r\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[6]\" coefficient=\"3.6580907875744093\"/>\r\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[7]\" coefficient=\"4.4758852605286785\"/>\r\n",
      "\t\t\t<CategoricalPredictor name=\"room_type\" value=\"Entire home/apt\" coefficient=\"24.220368721483727\"/>\r\n",
      "\t\t\t<CategoricalPredictor name=\"room_type\" value=\"Private room\" coefficient=\"-14.940185799040545\"/>\r\n",
      "\t\t\t<CategoricalPredictor name=\"host_is_super_host\" value=\"0.0\" coefficient=\"-5.449503933165154\"/>\r\n",
      "\t\t\t<CategoricalPredictor name=\"cancellation_policy\" value=\"strict\" coefficient=\"2.4637995016719128\"/>\r\n",
      "\t\t\t<CategoricalPredictor name=\"cancellation_policy\" value=\"moderate\" coefficient=\"-4.610653641271475\"/>\r\n",
      "\t\t\t<CategoricalPredictor name=\"cancellation_policy\" value=\"flexible\" coefficient=\"0.0\"/>\r\n",
      "\t\t\t<CategoricalPredictor name=\"cancellation_policy\" value=\"super_strict_30\" coefficient=\"67.08795384909708\"/>\r\n",
      "\t\t\t<CategoricalPredictor name=\"cancellation_policy\" value=\"super_strict_60\" coefficient=\"54.0815318306122\"/>\r\n",
      "\t\t\t<CategoricalPredictor name=\"cancellation_policy\" value=\"no_refunds\" coefficient=\"0.0\"/>\r\n",
      "\t\t\t<CategoricalPredictor name=\"instant_bookable\" value=\"0.0\" coefficient=\"6.945435378008621\"/>\r\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"Other\" coefficient=\"-10.746938303337094\"/>\r\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"NY\" coefficient=\"20.59184845921856\"/>\r\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"CA\" coefficient=\"12.516224727809934\"/>\r\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"Berlin\" coefficient=\"-49.611996932244686\"/>\r\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"IL\" coefficient=\"15.838880312369039\"/>\r\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"TX\" coefficient=\"33.53443377577336\"/>\r\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"WA\" coefficient=\"-8.07450223918869\"/>\r\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"DC\" coefficient=\"5.780899170890177\"/>\r\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"OR\" coefficient=\"-16.65636168171554\"/>\r\n",
      "\t\t</RegressionTable>\r\n",
      "\t</RegressionModel>\r\n",
      "</PMML>\r\n"
     ]
    }
   ],
   "source": [
    "!cat airbnb.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5:  Deploy the Pipeline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1 of 2:  Deploy with PipelineIO CLI!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "pip install -q pio-cli==0.37"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure CLI for Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "pio init-model --model-server-url=http://prediction-pmml.demo.pipeline.io --model-type=pmml \\\n",
    "    --model-namespace=cli --model-name=airbnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "pio deploy --model-version=v0 airbnb.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment Option 2:  REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "deploy_url = 'http://prediction-pmml.demo.pipeline.io/api/v1/model/deploy/pmml/rest/airbnb/v0'\n",
    "\n",
    "files = {'file': open('airbnb.model', 'rb')}\n",
    "\n",
    "response = requests.post(deploy_url, files=files)\n",
    "\n",
    "print(\"Success! %s\" % response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6:  Predict With Deployed Pipeline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Prediction Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = {\"bathrooms\":2.0, \n",
    "        \"bedrooms\":2.0, \n",
    "        \"security_deposit\":175.00, \n",
    "        \"cleaning_fee\":25.0, \n",
    "        \"extra_people\":1.0, \n",
    "        \"number_of_reviews\": 2.0, \n",
    "        \"square_feet\": 250.0, \n",
    "        \"review_scores_rating\": 2.0, \n",
    "        \"room_type\": \"Entire home/apt\", \n",
    "        \"host_is_super_host\": \"0.0\", \n",
    "        \"cancellation_policy\": \"flexible\", \n",
    "        \"instant_bookable\": \"1.0\", \n",
    "        \"state\": \"CA\" }\n",
    "\n",
    "json_data = json.dumps(data)\n",
    "\n",
    "with open('airbnb-predict-inputs.json', 'wt') as fh:\n",
    "    fh.write(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with CLI\n",
    "Note:  Run again if you see a fallback on the first try. (bug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "pio predict --model-version=v0 \\\n",
    "            --model-input-filename=airbnb-predict-inputs.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Note:  You may need to run this twice.\n",
    "#        A fallback will trigger the first time. (Bug)\n",
    "predict_url = 'http://prediction-pmml.demo.pipeline.io/api/v1/model/predict/pmml/rest/airbnb/v0'\n",
    "\n",
    "headers = {'content-type': 'application/json'}\n",
    "\n",
    "response = requests.post(predict_url, \n",
    "                         data=json_data, \n",
    "                         headers=headers)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7:  Monitor Model Servers through Dashboards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fallbacks and Circuit Breaker [Dashboard](http://hystrix.demo.pipeline.io/hystrix-dashboard/monitor/monitor.html?streams=%5B%7B%22name%22%3A%22Model%20Servers%22%2C%22stream%22%3A%22http%3A%2F%2Fturbine.demo.pipeline.io%2Fturbine.stream%22%2C%22auth%22%3A%22%22%2C%22delay%22%3A%22%22%7D%5D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "\n",
    "<iframe width=800 height=600 src=\"http://hystrix.demo.pipeline.io/hystrix-dashboard/monitor/monitor.html?streams=%5B%7B%22name%22%3A%22Model%20Servers%22%2C%22stream%22%3A%22http%3A%2F%2Fturbine.demo.pipeline.io%2Fturbine.stream%22%2C%22auth%22%3A%22%22%2C%22delay%22%3A%22%22%7D%5D\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafana Prediction Metrics [Dashboard](http://grafana.demo.pipeline.io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "\n",
    "<iframe width=800 height=600 src=\"http://grafana.demo.pipeline.io\"></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
